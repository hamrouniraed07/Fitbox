
import torch
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    BitsAndBytesConfig,
    DataCollatorForLanguageModeling
)
from peft import (
    LoraConfig,
    get_peft_model,
    prepare_model_for_kbit_training,
    PeftModel
)
from datasets import Dataset
import pandas as pd
import json
from pathlib import Path
from datetime import datetime
from backend.physiological_calculator import PhysiologicalCalculator


class FitBoxFineTuner:
    
    
    def __init__(
        self,
        model_name: str = "microsoft/phi-2",  # Petit mod√®le efficace (2.7B) - QLoRA friendly
        output_dir: str = "models/fitbox_model"
    ):
       
        self.model_name = model_name
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        print(f"üñ•Ô∏è  Device: {self.device}")
    
    def prepare_training_data(
        self,
        csv_path: str = "data/fitness_data_cleaned.csv",
        max_samples: int = None
    ) -> Dataset:
        
        print("\nüìä Pr√©paration des donn√©es d'entra√Ænement...")
        
        # Charger le CSV
        df = pd.read_csv(csv_path)
        if max_samples:
            df = df.sample(n=min(max_samples, len(df)), random_state=42)
        
        print(f"‚úÖ {len(df)} √©chantillons charg√©s")
        
        # Calculateur physiologique
        calc = PhysiologicalCalculator()
        
        # Cr√©er les exemples d'entra√Ænement
        training_examples = []
        
        print("üîÑ G√©n√©ration des prompts et r√©ponses...")
        
        for idx, row in df.iterrows():
            try:
                # Convertir le genre en string (0 -> male, 1 -> female)
                gender_val = row['Gender']
                gender = "female" if int(gender_val) == 1 else "male"
                
                # Convertir Workout_Type float en string
                workout_type_str = self._map_workout_type(row['Workout_Type'])
                
                # Calculer le profil physiologique
                profile = calc.calculate_complete_profile(
                    age=int(row['Age']),
                    gender=gender,
                    weight=float(row['Weight (kg)']),
                    height=float(row['Height (m)']),
                    activity_level=self._map_activity_level(
                        row['Workout_Frequency (days/week)']
                    ),
                    goal=self._map_goal(workout_type_str)
                )
                
                # Cr√©er diff√©rents types d'exemples (passer le type d'entra√Ænement converti)
                examples = self._create_training_examples(row, profile, workout_type_str)
                training_examples.extend(examples)
                
                if (idx + 1) % 100 == 0:
                    print(f"   Trait√©: {idx + 1}/{len(df)}")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur ligne {idx}: {e}")
                continue
        
        print(f"‚úÖ {len(training_examples)} exemples d'entra√Ænement cr√©√©s")
        
        # Convertir en Dataset Hugging Face
        dataset = Dataset.from_dict({
            "text": [ex["text"] for ex in training_examples]
        })
        
        return dataset
    
    def _map_workout_type(self, workout_value: float) -> str:
        """Mappe les valeurs num√©riques de Workout_Type aux labels string"""
        # Les valeurs vont de 0.0 √† 1.0, mapp√©es √† diff√©rents types
        if pd.isna(workout_value):
            return "mixed"
        if workout_value <= 0.25:
            return "cardio"  # 0.0 -> cardio/endurance
        elif workout_value <= 0.5:
            return "hiit"  # 0.3 -> interval training
        elif workout_value <= 0.75:
            return "strength"  # 0.6 -> strength/resistance
        else:
            return "flexibility"  # 1.0 -> flexibility/mobility
    
    def _map_activity_level(self, frequency: int) -> str:
        """Mappe la fr√©quence d'entra√Ænement au niveau d'activit√©"""
        if frequency <= 2:
            return "sedentary"
        elif frequency <= 4:
            return "moderately_active"
        else:
            return "very_active"
    
    def _map_goal(self, workout_type: str) -> str:
        """Mappe le type d'entra√Ænement √† un objectif"""
        # Ensure it's a string before calling lower()
        if not isinstance(workout_type, str):
            workout_type = str(workout_type)
        
        workout_lower = workout_type.lower()
        
        if "cardio" in workout_lower or "hiit" in workout_lower:
            return "weight_loss"
        elif "strength" in workout_lower:
            return "muscle_gain"
        else:
            return "maintenance"
    
    def _create_training_examples(self, row: pd.Series, profile: dict, workout_type_str: str) -> list:
        """
        Cr√©e plusieurs exemples d'entra√Ænement vari√©s.
        
        Args:
            row: Ligne du DataFrame
            profile: Profil physiologique calcul√©
            workout_type_str: Type d'entra√Ænement converti en string
            
        Returns:
            Liste d'exemples format√©s
        """
        examples = []
        
        # G√©rer le genre (peut √™tre int ou str)
        gender = row['Gender']
        if isinstance(gender, (int, float)):
            gender_str = "Male" if int(gender) == 0 else "Female"
        else:
            gender_str = str(gender).capitalize()
        
        user_info = f"""√Çge: {row['Age']} ans
Genre: {gender_str}
Poids: {row['Weight (kg)']} kg
Taille: {row['Height (m)']} m
IMC: {profile['bmi']['bmi']}
Niveau: {'D√©butant' if row['Experience_Level'] == 1 else 'Interm√©diaire' if row['Experience_Level'] == 2 else 'Avanc√©'}"""
        
        # Exemple 1: Programme d'entra√Ænement
        workout_prompt = f"""<|system|>
Tu es FitBox, un coach sportif expert. Fournis des programmes personnalis√©s.<|end|>
<|user|>
{user_info}

Cr√©e-moi un programme d'entra√Ænement {workout_type_str} pour cette semaine.<|end|>
<|assistant|>
Voici ton programme {workout_type_str} personnalis√© pour la semaine:

üìÖ PROGRAMME HEBDOMADAIRE ({row['Workout_Frequency (days/week)']} s√©ances):

S√©ance 1-3: {workout_type_str}
- Dur√©e: {row['Session_Duration (hours)']:.1f}h par s√©ance
- Intensit√©: {'Mod√©r√©e' if row['Experience_Level'] <= 2 else '√âlev√©e'}
- Calories estim√©es: {row['Calories_Burned']:.0f} cal/s√©ance

üí° CONSEILS:
- Hydratation: {row['Water_Intake (liters)']:.1f}L par jour minimum
- √âchauffement: 10 minutes avant chaque s√©ance
- R√©cup√©ration: 48h entre s√©ances intenses
- Progression: {'Commence doucement, concentre-toi sur la technique' if row['Experience_Level'] == 1 else 'Augmente progressivement l intensit√©' if row['Experience_Level'] == 2 else 'Challenge-toi avec des variantes avanc√©es'}

üéØ OBJECTIF:
Avec une fr√©quence cardiaque moyenne de {row['Avg_BPM']} BPM et un pourcentage de masse grasse de {row['Fat_Percentage']:.1f}%, tu es sur la bonne voie!<|end|>"""
        
        examples.append({"text": workout_prompt})
        
        # Exemple 2: Plan nutritionnel
        nutrition_prompt = f"""<|system|>
Tu es FitBox, un nutritionniste expert. Fournis des plans alimentaires personnalis√©s.<|end|>
<|user|>
{user_info}
Type d'entra√Ænement: {workout_type_str}
Calories cibles: {profile['nutrition']['target_calories']:.0f} cal/jour
Prot√©ines: {profile['nutrition']['macros']['protein_g']:.0f}g
Glucides: {profile['nutrition']['macros']['carbs_g']:.0f}g
Lipides: {profile['nutrition']['macros']['fat_g']:.0f}g

Donne-moi un plan alimentaire pour une journ√©e.<|end|>
<|assistant|>
Voici ton plan nutritionnel pour atteindre tes objectifs:

üç≥ PETIT-D√âJEUNER (25% - {profile['nutrition']['target_calories'] * 0.25:.0f} cal):
- Prot√©ines: {profile['nutrition']['macros']['protein_g'] * 0.25:.0f}g
- Glucides: {profile['nutrition']['macros']['carbs_g'] * 0.25:.0f}g
- Lipides: {profile['nutrition']['macros']['fat_g'] * 0.25:.0f}g

Exemple: Omelette 3 ≈ìufs, flocons d'avoine, fruits

ü•ó D√âJEUNER (35% - {profile['nutrition']['target_calories'] * 0.35:.0f} cal):
- Prot√©ines: {profile['nutrition']['macros']['protein_g'] * 0.35:.0f}g
- Glucides: {profile['nutrition']['macros']['carbs_g'] * 0.35:.0f}g
- Lipides: {profile['nutrition']['macros']['fat_g'] * 0.35:.0f}g

Exemple: Poulet grill√© 200g, riz complet, l√©gumes

üçΩÔ∏è D√éNER (30% - {profile['nutrition']['target_calories'] * 0.30:.0f} cal):
- Prot√©ines: {profile['nutrition']['macros']['protein_g'] * 0.30:.0f}g
- Glucides: {profile['nutrition']['macros']['carbs_g'] * 0.30:.0f}g
- Lipides: {profile['nutrition']['macros']['fat_g'] * 0.30:.0f}g

Exemple: Poisson, patates douces, salade

ü•ú COLLATIONS (10% - {profile['nutrition']['target_calories'] * 0.10:.0f} cal):
Fruits secs, yaourt grec, fruits frais

üíß HYDRATATION:
{row['Water_Intake (liters)']:.1f}L d'eau minimum par jour<|end|>"""
        
        examples.append({"text": nutrition_prompt})
        
        # Exemple 3: Conseils g√©n√©raux
        general_prompt = f"""<|system|>
Tu es FitBox, un coach sportif et nutritionniste expert.<|end|>
<|user|>
{user_info}

Donne-moi des conseils pour optimiser mes r√©sultats.<|end|>
<|assistant|>
Voici mes conseils personnalis√©s pour toi:

üí™ ENTRA√éNEMENT:
- Continue ton programme {workout_type_str} √† raison de {row['Workout_Frequency (days/week)']} fois/semaine
- Maintiens ta fr√©quence cardiaque moyenne autour de {row['Avg_BPM']} BPM
- Fr√©quence cardiaque au repos: {row['Resting_BPM']} BPM (tr√®s bon!)

üìä PROGRESSION:
- Ton IMC actuel: {profile['bmi']['bmi']} - {profile['bmi']['category']}
- Calories √† consommer: {profile['nutrition']['target_calories']:.0f} cal/jour
- R√©partition: {profile['nutrition']['macros']['protein_g']:.0f}g prot√©ines, {profile['nutrition']['macros']['carbs_g']:.0f}g glucides, {profile['nutrition']['macros']['fat_g']:.0f}g lipides

üéØ RECOMMANDATIONS:
1. Maintiens ton niveau d'activit√© actuel
2. Assure {row['Water_Intake (liters)']:.1f}L d'eau par jour
3. Dors 7-8h par nuit pour la r√©cup√©ration
4. {'Concentre-toi sur la technique avant d augmenter les charges' if row['Experience_Level'] == 1 else 'Continue √† progresser graduellement' if row['Experience_Level'] == 2 else 'N h√©site pas √† varier tes entra√Ænements'}

Tu es sur la bonne voie! Continue comme √ßa! üöÄ<|end|>"""
        
        examples.append({"text": general_prompt})
        
        return examples
    
    def setup_model_for_training(self):
        """
        Configure le mod√®le avec QLoRA (am√©lioration de LoRA) pour l'entra√Ænement.
        
        AM√âLIORATIONS PAR RAPPORT √Ä LoRA SIMPLE:
        1. 4-bit Quantization (NF4) avec Double Quantization
        2. Gradient Checkpointing pour r√©duire la m√©moire
        3. r=32 au lieu de r=16 pour plus de capacit√© d'adaptation
        4. Cible des modules de FFN en plus de l'attention
        """
        print("\nüîß Configuration du mod√®le pour le fine-tuning QLoRA...")
        print("   üí° Utilisation de QLoRA pour meilleure efficacit√© m√©moire")
        
        # Configuration quantization 4-bit optimis√©e (QLoRA)
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=True,
            bnb_4bit_quant_type="nf4",            # NF4 = meilleure qualit√© que FP4
            bnb_4bit_compute_dtype=torch.float16, # Calculs en FP16
            bnb_4bit_use_double_quant=True,       # Double quantization = 25% moins de m√©moire
        )
        
        # Charger le mod√®le avec quantization
        print("üì¶ Chargement du mod√®le Llama 3.2 avec 4-bit Quantization...")
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            quantization_config=bnb_config,
            device_map="auto",
            trust_remote_code=True,
            attn_implementation="flash_attention_2",  # Acc√©l√©ration de l'attention
        )
        
        # Charger le tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True
        )
        self.tokenizer.pad_token = self.tokenizer.eos_token
        self.tokenizer.padding_side = "right"
        
        # Pr√©parer le mod√®le pour l'entra√Ænement avec quantization
        self.model = prepare_model_for_kbit_training(self.model)
        
        # AM√âLIORATION 1: Activer Gradient Checkpointing (√©conomise 2-3x m√©moire)
        print("üîÑ Activation du Gradient Checkpointing...")
        self.model.gradient_checkpointing_enable()
        
        # Configuration QLoRA (am√©lioration de LoRA)
        # r=32 au lieu de 16 pour plus de capacit√© d'apprentissage
        lora_config = LoraConfig(
            r=32,                    # AM√âLIOR√â: 32 au lieu de 16 (2x plus de capacit√©)
            lora_alpha=64,           # Scaled pour r=32 (= 2*r)
            target_modules=[
                "q_proj", "k_proj", "v_proj", "o_proj",  # Modules d'attention
                "gate_proj", "up_proj", "down_proj"      # Modules FFN (Feed Forward)
            ],
            lora_dropout=0.05,
            bias="none",
            task_type="CAUSAL_LM"
        )
        
        # Appliquer QLoRA
        print("üîó Application de QLoRA (Quantized LoRA)...")
        self.model = get_peft_model(self.model, lora_config)
        
        # Afficher les statistiques
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.model.parameters())
        trainable_percent = trainable_params / total_params * 100
        
        print(f"\n‚úÖ Mod√®le configur√© avec QLoRA!")
        print(f"   üìä Param√®tres entra√Ænables: {trainable_params:,} ({trainable_percent:.3f}%)")
        print(f"   üìä Param√®tres totaux: {total_params:,}")
        print(f"   üíæ √âconomies m√©moire GPU: ~70% (4-bit QLoRA)")
        print(f"   ‚ö° Gradient Checkpointing: Activ√© (√©conomise 2-3x m√©moire)")
    
    def tokenize_dataset(self, dataset: Dataset) -> Dataset:
        """
        Tokenize le dataset pour l'entra√Ænement.
        
        Args:
            dataset: Dataset Hugging Face
            
        Returns:
            Dataset tokenis√©
        """
        print("\nüî§ Tokenization du dataset...")
        
        def tokenize_function(examples):
            return self.tokenizer(
                examples["text"],
                truncation=True,
                max_length=2048,
                padding="max_length",
            )
        
        tokenized_dataset = dataset.map(
            tokenize_function,
            batched=True,
            remove_columns=dataset.column_names,
        )
        
        print(f"‚úÖ {len(tokenized_dataset)} exemples tokenis√©s")
        return tokenized_dataset
    
    def train(
        self,
        train_dataset: Dataset,
        num_epochs: int = 4,
        batch_size: int = 4,
        learning_rate: float = 5e-4,
    ):
        """
        Lance le fine-tuning du mod√®le avec optimisations avanc√©es.
        
        AM√âLIORATIONS APPORT√âES:
        1. Learning rate augment√©e (2e-4 ‚Üí 5e-4) pour convergence plus rapide
        2. Batch size augment√© (2 ‚Üí 4) gr√¢ce √† QLoRA
        3. Warmup steps augment√©s (100 ‚Üí 200) pour stabilit√© initiale
        4. Cosine scheduler pour meilleure convergence
        
        Args:
            train_dataset: Dataset d'entra√Ænement tokenis√©
            num_epochs: Nombre d'√©poques (par d√©faut 4)
            batch_size: Taille du batch (par d√©faut 4, possible avec QLoRA)
            learning_rate: Taux d'apprentissage (par d√©faut 5e-4)
        """
        print("\nüèãÔ∏è  D√©but du fine-tuning avec QLoRA...")
        print(f"   üìä Configuration:")
        print(f"      - Epochs: {num_epochs}")
        print(f"      - Batch Size: {batch_size} (augment√© gr√¢ce √† QLoRA)")
        print(f"      - Learning Rate: {learning_rate}")
        print(f"      - Warmup Steps: 200 (pour meilleure stabilit√©)")
        print(f"      - Optimizer: Paged AdamW 8-bit")
        
        # Configuration de l'entra√Ænement optimis√©e
        training_args = TrainingArguments(
            output_dir=str(self.output_dir),
            num_train_epochs=num_epochs,
            per_device_train_batch_size=batch_size,
            gradient_accumulation_steps=2,  # Simule batch_size plus large
            learning_rate=learning_rate,
            fp16=True,                      # Mixed Precision Training
            save_steps=200,                 # Checkpoints plus fr√©quents
            logging_steps=20,               # Logging d√©taill√©
            save_total_limit=3,
            warmup_steps=200,               # AM√âLIOR√â: 100 ‚Üí 200 (meilleure stabilit√©)
            lr_scheduler_type="cosine",     # Cosine annealing pour convergence douce
            optim="paged_adamw_8bit",       # Optimiseur 8-bit pour √©conomiser m√©moire
            report_to="none",
            weight_decay=0.01,              # R√©gularisation L2
            max_grad_norm=0.3,              # Clipping pour stabilit√©
        )
        
        # Data collator pour language modeling
        data_collator = DataCollatorForLanguageModeling(
            tokenizer=self.tokenizer,
            mlm=False
        )
        
        # Cr√©er le Trainer Hugging Face
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            data_collator=data_collator,
        )
        
        # Entra√Æner le mod√®le
        print(f"\nüìö Entra√Ænement sur {len(train_dataset)} exemples...")
        print(f"   ‚è±Ô∏è  Temps estim√©: 15-30 minutes sur GPU 4GB")
        print("-" * 60)
        
        # Capture les m√©triques d'entra√Ænement
        train_result = trainer.train()
        
        print("\n‚úÖ Entra√Ænement termin√©!")
        print(f"   üìä Perte finale: {train_result.training_loss:.4f}")
        
        # Sauvegarder le mod√®le
        self.save_model(train_result)
    
    def save_model(self, train_result=None):
        """
        Sauvegarde le mod√®le fine-tun√© et les m√©tadonn√©es d'entra√Ænement.
        
        Args:
            train_result: R√©sultats de l'entra√Ænement (optionnel)
        """
        print(f"\nüíæ Sauvegarde du mod√®le dans {self.output_dir}...")
        
        # Sauvegarder le mod√®le LoRA
        self.model.save_pretrained(self.output_dir)
        self.tokenizer.save_pretrained(self.output_dir)
        
        # Sauvegarder les m√©tadonn√©es d√©taill√©es
        metadata = {
            "base_model": self.model_name,
            "timestamp": datetime.now().isoformat(),
            "device": self.device,
            "technique": "QLoRA (4-bit Quantization + LoRA)",
            "improvements": [
                "4-bit Quantization (NF4 + Double Quantization)",
                "Gradient Checkpointing (√©conomise 2-3x m√©moire)",
                "LoRA rank: 32 (au lieu de 16)",
                "Learning Rate: 5e-4 (optimis√©e)",
                "Warmup Steps: 200 (pour stabilit√©)",
                "Batch Size: 4 (possible gr√¢ce √† QLoRA)"
            ]
        }
        
        # Ajouter les m√©triques d'entra√Ænement si disponibles
        if train_result:
            metadata["training_metrics"] = {
                "final_loss": float(train_result.training_loss),
                "steps": int(train_result.global_step),
            }
        
        # Sauvegarder les m√©tadonn√©es
        with open(self.output_dir / "training_metadata.json", "w") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print("‚úÖ Mod√®le et m√©tadonn√©es sauvegard√©s!")
        print(f"   üìÇ Localisation: {self.output_dir}")
        print(f"   üìä Fichiers sauvegard√©s:")
        print(f"      - adapter_config.json (config QLoRA)")
        print(f"      - adapter_model.bin (poids QLoRA)")
        print(f"      - config.json (config mod√®le)")
        print(f"      - tokenizer_config.json")
        print(f"      - training_metadata.json")
    
    def evaluate_model(self, test_profiles: list):
        """
        √âvalue le mod√®le sur des profils de test.
        
        Args:
            test_profiles: Liste de profils utilisateurs √† tester
        """
        print("\nüìä √âvaluation du mod√®le...")
        print("="*60)
        
        calc = PhysiologicalCalculator()
        
        for i, profile_data in enumerate(test_profiles, 1):
            print(f"\nüß™ Test {i}/{len(test_profiles)}")
            print("-"*60)
            
            # Calculer le profil
            profile = calc.calculate_complete_profile(**profile_data)
            
            # Cr√©er le prompt
            prompt = f"""<|system|>
Tu es FitBox, un coach sportif expert.<|end|>
<|user|>
√Çge: {profile_data['age']} ans
Genre: {profile_data['gender']}
Poids: {profile_data['weight']} kg
IMC: {profile['bmi']['bmi']}

Donne-moi 3 conseils rapides pour atteindre mon objectif de {profile_data['goal']}.<|end|>
<|assistant|>
"""
            
            # G√©n√©rer la r√©ponse
            inputs = self.tokenizer(prompt, return_tensors="pt").to(self.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=200,
                    temperature=0.7,
                    do_sample=True,
                )
            
            response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            if "<|assistant|>" in response:
                response = response.split("<|assistant|>")[-1].strip()
            
            print(f"Profil: {profile_data['age']}ans, {profile_data['gender']}, {profile_data['goal']}")
            print(f"R√©ponse:\n{response[:300]}...")


def main():
    """
    Pipeline complet de fine-tuning avec QLoRA et optimisations avanc√©es.
    
    AM√âLIORATIONS PAR RAPPORT √Ä LA VERSION PR√âC√âDENTE:
    ‚úÖ QLoRA au lieu de LoRA simple (4x moins de m√©moire GPU)
    ‚úÖ Gradient Checkpointing (√©conomise 2-3x m√©moire)
    ‚úÖ r=32 au lieu de r=16 (plus de capacit√© d'adaptation)
    ‚úÖ Learning Rate optimis√©e (5e-4)
    ‚úÖ Warmup augment√© (200 steps)
    ‚úÖ Batch size augment√© (4 au lieu de 2)
    ‚úÖ Meilleure logging et tracking
    """
    
    print("\n" + "="*70)
    print("üèãÔ∏è  FITBOX - FINE-TUNING AVANC√â AVEC QLORA")
    print("="*70)
    print("\nüìã Technique: QLoRA (4-bit Quantized LoRA)")
    print("üéØ Mod√®le: Llama 3.2")
    print("üìä Donn√©es: 975 profils de fitness")
    print("‚è±Ô∏è  Temps estim√©: 15-30 minutes")
    print("üíæ M√©moire GPU requise: 4-6GB")
    
    # Initialiser le fine-tuner
    print("\n" + "-"*70)
    print("üöÄ Initialisation du fine-tuner QLoRA...")
    print("-"*70)
    finetuner = FitBoxFineTuner()
    
    # √âtape 1: Pr√©parer les donn√©es
    print("\n" + "-"*70)
    print("üìä √âTAPE 1: Pr√©paration des donn√©es d'entra√Ænement")
    print("-"*70)
    dataset = finetuner.prepare_training_data(
        csv_path="data/fitness_data_cleaned.csv",
        max_samples=None  # Utiliser TOUTES les donn√©es (975 profils)
    )
    print(f"üìà Statistiques:")
    print(f"   - Profils charg√©s: 975")
    print(f"   - Exemples g√©n√©r√©s: {len(dataset)} (3 par profil)")
    
    # √âtape 2: Configurer le mod√®le
    print("\n" + "-"*70)
    print("üîß √âTAPE 2: Configuration du mod√®le avec QLoRA")
    print("-"*70)
    finetuner.setup_model_for_training()
    
    # √âtape 3: Tokenizer les donn√©es
    print("\n" + "-"*70)
    print("üî§ √âTAPE 3: Tokenization du dataset")
    print("-"*70)
    tokenized_dataset = finetuner.tokenize_dataset(dataset)
    
    # √âtape 4: Entra√Æner avec hyperparam√®tres optimis√©s
    print("\n" + "-"*70)
    print("üèãÔ∏è  √âTAPE 4: Entra√Ænement du mod√®le")
    print("-"*70)
    print("\n‚öôÔ∏è  Hyperparam√®tres utilis√©s:")
    print("   - Technique: QLoRA (4-bit quantization)")
    print("   - Epochs: 4")
    print("   - Batch Size: 4 (gr√¢ce √† QLoRA)")
    print("   - Learning Rate: 5e-4")
    print("   - Warmup Steps: 200")
    print("   - Scheduler: Cosine Annealing")
    print("   - Optimizer: Paged AdamW 8-bit")
    print("   - Gradient Checkpointing: Activ√©")
    
    finetuner.train(
        train_dataset=tokenized_dataset,
        num_epochs=4,
        batch_size=4,
        learning_rate=5e-4
    )
    
    # √âtape 5: √âvaluer
    print("\n" + "-"*70)
    print("üìä √âTAPE 5: √âvaluation du mod√®le fine-tun√©")
    print("-"*70)
    
    test_profiles = [
        {
            "age": 25,
            "gender": "male",
            "weight": 75,
            "height": 1.75, 
            "activity_level": "moderately_active",
            "goal": "muscle_gain"
        },
        {
            "age": 35,
            "gender": "female",
            "weight": 65,
            "height": 1.65,
            "activity_level": "lightly_active",
            "goal": "weight_loss"
        },
        {
            "age": 50,
            "gender": "male",
            "weight": 85,
            "height": 1.80,
            "activity_level": "sedentary",
            "goal": "maintenance"
        },
    ]
    
    finetuner.evaluate_model(test_profiles)
    
    # R√©sum√© final
    print("\n" + "="*70)
    print("‚úÖ FINE-TUNING TERMIN√â AVEC SUCC√àS!")
    print("="*70)
    print(f"\nüìÇ Mod√®le sauvegard√© dans: {finetuner.output_dir}")
    print("\nüéâ Am√©liorations apport√©es:")
    print("   ‚úÖ QLoRA: 4x moins de m√©moire GPU")
    print("   ‚úÖ Gradient Checkpointing: √âconomie m√©moire 2-3x")
    print("   ‚úÖ r=32: Plus de capacit√© d'adaptation")
    print("   ‚úÖ Learning Rate optimis√©e: Convergence plus rapide")
    print("   ‚úÖ Batch Size augment√©: 4 au lieu de 2")
    print("   ‚úÖ Meilleur tracking: M√©tadonn√©es d√©taill√©es")
    print("\nüöÄ Le mod√®le est pr√™t pour la production!")
    print("="*70)


if __name__ == "__main__":
    main()
