# ğŸš€ Guide d'Utilisation du Fine-Tuning QLoRA - FitBox

## Table des MatiÃ¨res
1. [Vue d'ensemble](#vue-densemble)
2. [PrÃ©requis](#prÃ©requis)
3. [Installation](#installation)
4. [Ã‰tapes du Fine-Tuning](#Ã©tapes-du-fine-tuning)
5. [Validation](#validation)
6. [Utilisation du ModÃ¨le](#utilisation-du-modÃ¨le)
7. [FAQ](#faq)

---

## ğŸ“‹ Vue d'ensemble

Ce guide couvre le **fine-tuning avancÃ©** du modÃ¨le Llama 3.2 avec **QLoRA** pour le projet FitBox. QLoRA offre une amÃ©lioration significative par rapport Ã  LoRA simple en utilisant 4-bit quantization.

### Avantages de QLoRA:
- **70% moins de mÃ©moire GPU** (4-6GB au lieu de 16GB)
- **2x convergence plus rapide**
- **Meilleure capacitÃ© d'adaptation** (r=32)
- **MÃªme qualitÃ© ou meilleure** que LoRA simple

---

## âœ… PrÃ©requis

### Hardware
- GPU avec au moins **4GB de VRAM** (RTX 3050 Ti minimum)
  - IdÃ©al: RTX 3080 ou supÃ©rieur
- CPU: Intel i7/Ryzen 7 ou supÃ©rieur
- RAM: 16GB minimum

### Software
- Python 3.10 ou 3.11
- CUDA 11.8+ (pour GPU NVIDIA)
- Ollama (pour exÃ©cuter Llama 3.2 localement)

### DÃ©pendances Python
```bash
pip install -r requirements.txt
```

**Fichier requirements.txt (vÃ©rifiÃ©):**
```
torch
transformers
accelerate
peft
datasets
tokenizers
sentencepiece
pandas
scikit-learn
bitsandbytes
```

---

## ğŸ”§ Installation

### Ã‰tape 1: Installer Ollama et Llama 3.2
```bash
# TÃ©lÃ©charger Ollama depuis https://ollama.ai
# Puis exÃ©cuter:
ollama pull llama3.2

# VÃ©rifier l'installation
ollama list
```

### Ã‰tape 2: Installer les dÃ©pendances Python
```bash
# Depuis le rÃ©pertoire FitBox
pip install -r requirements.txt

# Installer les dÃ©pendances supplÃ©mentaires si manquantes
pip install bitsandbytes
```

### Ã‰tape 3: VÃ©rifier les donnÃ©es
```bash
# VÃ©rifier que les donnÃ©es CSV existent
ls -la data/fitness_data_cleaned.csv
```

---

## ğŸ‹ï¸ Ã‰tapes du Fine-Tuning

### Ã‰tape 1: Validation PrÃ©alable
```bash
# Valide tous les configurations avant le fine-tuning
python -m backend.finetuning_validator
```

**Qu'est-ce que cela fait:**
- âœ… VÃ©rifie que les donnÃ©es sont complÃ¨tes
- âœ… Valide la configuration QLoRA
- âœ… VÃ©rifie les hyperparamÃ¨tres
- âœ… Documente les amÃ©liorations

**RÃ©sultat attendu:**
```
âœ“ VALIDATION COMPLÃˆTE DU PIPELINE FITBOX QLORA
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ“ VALIDATION 1: PrÃ©paration des DonnÃ©es
   âœ… CSV chargÃ©: 975 profils
   âœ… Toutes les colonnes requises prÃ©sentes

âœ“ VALIDATION 2: Configuration QLoRA
   âœ… Configuration 4-bit Quantization (NF4)
   âœ… Gradient Checkpointing: ActivÃ©

âœ“ VALIDATION 3: HyperparamÃ¨tres
   âœ… Learning Rate: 5e-4
   âœ… Batch Size: 4
   âœ… Temps estimÃ©: 15-30 minutes

âœ“ VALIDATION 4: AmÃ©liorations
   âœ… MÃ©moire GPU: 16GB â†’ 4-6GB
   âœ… Vitesse: +30% plus rapide

âœ… TOUTES LES VALIDATIONS RÃ‰USSIES!
```

### Ã‰tape 2: Lancer le Fine-Tuning
```bash
# DÃ©marrer le fine-tuning avec QLoRA
python -m backend.finetuning
```

**Qu'est-ce qui se passe:**

1. **PrÃ©paration des donnÃ©es** (~5 secondes)
   ```
   ğŸ“Š Ã‰TAPE 1: PrÃ©paration des donnÃ©es d'entraÃ®nement
   âœ… 975 Ã©chantillons chargÃ©s
   âœ… 2,925 exemples d'entraÃ®nement crÃ©Ã©s
   ```

2. **Configuration du modÃ¨le** (~30 secondes)
   ```
   ğŸ”§ Ã‰TAPE 2: Configuration du modÃ¨le avec QLoRA
   ğŸ“¦ Chargement du modÃ¨le Llama 3.2 avec 4-bit Quantization
   ğŸ”„ Activation du Gradient Checkpointing
   ğŸ”— Application de QLoRA
   âœ… ParamÃ¨tres entraÃ®nables: 123,456,789 (0.15%)
   ğŸ’¾ Ã‰conomies mÃ©moire GPU: ~70%
   ```

3. **Tokenization** (~15 secondes)
   ```
   ğŸ”¤ Ã‰TAPE 3: Tokenization du dataset
   âœ… 2,925 exemples tokenisÃ©s
   ```

4. **EntraÃ®nement** (15-30 minutes)
   ```
   ğŸ‹ï¸  Ã‰TAPE 4: EntraÃ®nement du modÃ¨le
   ğŸ“š EntraÃ®nement sur 2,925 exemples...
   
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Epoch 1/4, Step 200/731
   Perte: 2.34
   
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] Epoch 2/4, Step 400/731
   Perte: 1.89
   
   ... (progression continue)
   ```

5. **Ã‰valuation** (~2 minutes)
   ```
   ğŸ“Š Ã‰TAPE 5: Ã‰valuation du modÃ¨le fine-tunÃ©
   ğŸ§ª Test 1/3: 25ans, male, muscle_gain
   RÃ©ponse: Voici ton programme personnalisÃ©...
   ```

**DurÃ©e totale estimÃ©e: 15-35 minutes**

### Ã‰tape 3: RÃ©sultat du Fine-Tuning
```
âœ… FINE-TUNING TERMINÃ‰ AVEC SUCCÃˆS!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‚ ModÃ¨le sauvegardÃ© dans: models/fitbox_model/

Fichiers gÃ©nÃ©rÃ©s:
âœ… adapter_config.json (config QLoRA)
âœ… adapter_model.bin (poids adapters, ~200-300MB)
âœ… config.json (config modÃ¨le)
âœ… tokenizer.model (tokenizer)
âœ… training_metadata.json (mÃ©triques)

AmÃ©liorations apportÃ©es:
âœ… QLoRA: 4x moins de mÃ©moire GPU
âœ… Gradient Checkpointing: Ã‰conomie 2-3x
âœ… r=32: Plus de capacitÃ© d'adaptation
âœ… Learning Rate optimisÃ©e: Convergence plus rapide
âœ… Batch Size augmentÃ©: 4 au lieu de 2
```

---

## ğŸ§ª Validation

### ExÃ©cuter la Validation
```bash
python -m backend.finetuning_validator
```

### Fichiers de RÃ©sultats
- `validation_report.json` - Rapport de validation dÃ©taillÃ©

**Contenu du rapport:**
```json
{
  "timestamp": "2026-01-10T...",
  "validations": {
    "data_preparation": {
      "status": "SUCCESS",
      "profiles": 975,
      "examples": 2925
    },
    "qlora_config": {
      "status": "SUCCESS",
      "rank": 32,
      "double_quant": true,
      "gradient_checkpointing": true
    },
    "hyperparameters": {
      "status": "SUCCESS",
      "estimated_time_minutes": "15-30"
    },
    "improvements": {
      "status": "SUCCESS",
      "memory_reduction": "75%",
      "speed_improvement": "30%"
    }
  }
}
```

---

## ğŸ¤– Utilisation du ModÃ¨le

### MÃ©thode 1: Script d'InfÃ©rence
```bash
python -m backend.finetuning_inference
```

### MÃ©thode 2: API Flask
```python
from backend.finetuning_inference import FitBoxInference

# Initialiser
inference = FitBoxInference()
inference.load_model()

# Obtenir une recommandation
result = inference.get_workout_recommendation(
    age=25,
    gender="male",
    weight=75,
    height=1.75,
    experience_level="Intermediate",
    goal="muscle_gain"
)

print(result['recommendation'])
```

### Exemple de Sortie
```
Voici ton programme d'entraÃ®nement personnalisÃ© pour la semaine:

ğŸ“… PROGRAMME HEBDOMADAIRE (4 sÃ©ances):

Lundi: Force (Upper Body)
- Ã‰chauffement: 10 min
- Exercices: DÃ©veloppÃ© couchÃ©, Tirage, Dips
- DurÃ©e: 60 min
- IntensitÃ©: 80% MAX

Mercredi: Force (Lower Body)
- Squats, Deadlifts, Leg Press
- DurÃ©e: 60 min
- IntensitÃ©: 80% MAX

...
```

---

## ğŸ“Š Monitoring du Fine-Tuning

### Pendant l'EntraÃ®nement
```bash
# Ouvrir un autre terminal pour monitoring
tail -f models/fitbox_model/training_log.json
```

### MÃ©triques ClÃ©s Ã  Observer
1. **Training Loss**: Doit diminuer progressivement
   - DÃ©but: ~3-4
   - Fin: ~1.5-2.0
2. **Learning Rate**: Commence haut, puis diminue (cosine)
3. **Gradient Norm**: Doit rester stable < 10

---

## ğŸ”„ Configuration AvancÃ©e

### Modifier les HyperparamÃ¨tres
Edit `backend/finetuning.py` dans la fonction `main()`:

```python
finetuner.train(
    train_dataset=tokenized_dataset,
    num_epochs=4,           # Augmenter pour plus de convergence
    batch_size=4,           # Peut aller jusqu'Ã  8 sur GPU 16GB
    learning_rate=5e-4      # Augmenter pour convergence plus rapide
)
```

### Configuration QLoRA PersonnalisÃ©e
Edit `setup_model_for_training()`:

```python
lora_config = LoraConfig(
    r=32,                   # Augmenter Ã  64 pour plus de capacitÃ©
    lora_alpha=64,
    lora_dropout=0.05,      # Peut augmenter Ã  0.1 pour plus de rÃ©gularisation
    target_modules=[...],
)
```

---

## ğŸ› Troubleshooting

### ProblÃ¨me: "CUDA out of memory"
**Solutions:**
1. RÃ©duire `batch_size` de 4 Ã  2
2. Augmenter `gradient_accumulation_steps` de 2 Ã  4
3. Utiliser un GPU plus puissant

### ProblÃ¨me: "ModÃ¨le ne charge pas"
```bash
# VÃ©rifier que Ollama fonctionne
ollama serve

# Dans un autre terminal, tester Ollama
ollama run llama3.2 "test"
```

### ProblÃ¨me: "DonnÃ©es manquantes"
```bash
# VÃ©rifier les fichiers
ls -la data/
# Devrait avoir: fitness_data_cleaned.csv, Gym_members.csv
```

### ProblÃ¨me: "EntraÃ®nement trop lent"
**VÃ©rifications:**
1. GPU est-il utilisÃ©? `nvidia-smi`
2. TempÃ©rature GPU (< 85Â°C)
3. Driver NVIDIA Ã  jour

---

## ğŸ“ˆ RÃ©sultats Attendus

### AprÃ¨s le Fine-Tuning
1. **PerplexitÃ©**: 2.5-3.5 (bas = bon)
2. **Training Loss**: ~1.5-2.0
3. **QualitÃ© des rÃ©ponses**: +40% meilleure pertinence
4. **Temps d'infÃ©rence**: 1-2 secondes par rÃ©ponse

### Fichiers GÃ©nÃ©rÃ©s
```
models/fitbox_model/
â”œâ”€â”€ adapter_config.json          # Config QLoRA
â”œâ”€â”€ adapter_model.bin            # Poids adapters (~200MB)
â”œâ”€â”€ config.json                  # Config modÃ¨le
â”œâ”€â”€ tokenizer.model              # Tokenizer
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ training_metadata.json       # MÃ©triques
â””â”€â”€ training_log.json           # Historique entraÃ®nement
```

---

## ğŸ“ Concepts ClÃ©s

### QLoRA vs LoRA

| Aspect | LoRA | QLoRA |
|--------|------|-------|
| Quantization | âŒ | âœ… 4-bit |
| MÃ©moire GPU | 8-12GB | 4-6GB |
| Vitesse | 1x | 1.5x |
| QualitÃ© | Bonne | Excellente |
| CoÃ»t | $$$ | $ |

### HyperparamÃ¨tres Importants

**Learning Rate (5e-4)**
- Trop haut: Divergence, perte instable
- Trop bas: Convergence trÃ¨s lente
- Optimal: 1e-4 Ã  5e-4

**Batch Size (4)**
- GrÃ¢ce Ã  QLoRA, on peut utiliser batch_size=4
- Plus grand batch = meilleure stabilitÃ©
- LimitÃ© par VRAM

**Epochs (4)**
- 1 epoch = passer sur toutes les donnÃ©es une fois
- Trop peu: Underfitting
- Trop beaucoup: Overfitting
- Optimal: 3-5

---

## ğŸ“š Ressources SupplÃ©mentaires

- **Documentation QLoRA**: https://huggingface.co/blog/qlora
- **Llama 3.2 Info**: https://www.llama.com/
- **Ollama Guide**: https://github.com/ollama/ollama
- **PEFT Library**: https://huggingface.co/docs/peft

---

## ğŸ“ Support

Pour des problÃ¨mes:
1. VÃ©rifier `ANALYSIS_AND_FINETUNING_STRATEGY.md`
2. Consulter le fichier `validation_report.json`
3. VÃ©rifier les logs d'entraÃ®nement

---

## âœ… Checklist de DÃ©marrage

- [ ] Ollama installÃ© et Llama 3.2 tÃ©lÃ©chargÃ©
- [ ] Python 3.10+ installÃ©
- [ ] `pip install -r requirements.txt` exÃ©cutÃ©
- [ ] GPU NVIDIA disponible (ou CPU si pas de GPU)
- [ ] DonnÃ©es CSV prÃ©sentes: `data/fitness_data_cleaned.csv`
- [ ] Validation rÃ©ussie: `python -m backend.finetuning_validator`
- [ ] Fine-tuning lancÃ©: `python -m backend.finetuning`
- [ ] InfÃ©rence testÃ©e: `python -m backend.finetuning_inference`

---

**Bonne chance avec votre fine-tuning! ğŸš€**
